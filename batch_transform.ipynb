{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference\n",
    "we will do batch inference using a model that has been trained. there are a couple of ways we can do this.\n",
    "\n",
    "1. Continue in the training notebook right after training (easy but not practical)\n",
    "2. The way we see below, more practical and transalatable to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='randomcutforest-2022-03-03-19-12-44-762'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=\"feidemo\"\n",
    "prefix=\"veritoll\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#batch-transform-data-processing-example-select-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................\n",
      "\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loading entry points\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loading entry points\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Number of server workers: 1\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loading model...\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Random Cut Forest model loaded.\u001b[0m\n",
      "\u001b[34mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 1, shingle_size: 1, trees_num_nodes: [353, 359, 349, 339, 357, 361, 359, 363, 373, 373, 355, 371, 363, 337, 359, 361, 371, 327, 361, 357, 361, 353, 349, 369, 357, 361, 365, 363, 345, 369, 345, 361, 353, 343, 357, 349, 337, 341, 365, 365, 359, 349, 359, 337, 355, 353, 345, 361, 361, 363, ], trees_depth: [18, 16, 16, 14, 15, 17, 19, 17, 19, 17, 15, 15, 15, 16, 15, 15, 19, 13, 19, 16, 21, 16, 15, 15, 16, 19, 17, 15, 16, 18, 19, 15, 16, 16, 20, 24, 18, 17, 17, 17, 16, 17, 17, 17, 19, 15, 21, 16, 21, 15, ], max_num_nodes: 373, min_num_nodes: 327, avg_num_nodes: 355, max_tree_depth: 24, min_tree_depth: 13, avg_tree_depth: 16, mem_size: 1851440}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593407.7923996, \"EndTime\": 1646593408.4161294, \"Dimensions\": {}, \"Metrics\": {\"model.bytes\": {\"sum\": 1851440.0, \"count\": 1, \"min\": 1851440, \"max\": 1851440}, \"deserialize_model.time\": {\"sum\": 46.7991828918457, \"count\": 1, \"min\": 46.7991828918457, \"max\": 46.7991828918457}}}\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Number of server workers: 1\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loading model...\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Random Cut Forest model loaded.\u001b[0m\n",
      "\u001b[35mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 1, shingle_size: 1, trees_num_nodes: [353, 359, 349, 339, 357, 361, 359, 363, 373, 373, 355, 371, 363, 337, 359, 361, 371, 327, 361, 357, 361, 353, 349, 369, 357, 361, 365, 363, 345, 369, 345, 361, 353, 343, 357, 349, 337, 341, 365, 365, 359, 349, 359, 337, 355, 353, 345, 361, 361, 363, ], trees_depth: [18, 16, 16, 14, 15, 17, 19, 17, 19, 17, 15, 15, 15, 16, 15, 15, 19, 13, 19, 16, 21, 16, 15, 15, 16, 19, 17, 15, 16, 18, 19, 15, 16, 16, 20, 24, 18, 17, 17, 17, 16, 17, 17, 17, 19, 15, 21, 16, 21, 15, ], max_num_nodes: 373, min_num_nodes: 327, avg_num_nodes: 355, max_tree_depth: 24, min_tree_depth: 13, avg_tree_depth: 16, mem_size: 1851440}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593407.7923996, \"EndTime\": 1646593408.4161294, \"Dimensions\": {}, \"Metrics\": {\"model.bytes\": {\"sum\": 1851440.0, \"count\": 1, \"min\": 1851440, \"max\": 1851440}, \"deserialize_model.time\": {\"sum\": 46.7991828918457, \"count\": 1, \"min\": 46.7991828918457, \"max\": 46.7991828918457}}}\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593408.4164748, \"EndTime\": 1646593410.1156788, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593408.4164748, \"EndTime\": 1646593410.1156788, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[32m2022-03-06T19:03:30.124:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593410.1158593, \"EndTime\": 1646593412.5239465, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"evaluate.time\": {\"sum\": 1276.0496139526367, \"count\": 1, \"min\": 1276.0496139526367, \"max\": 1276.0496139526367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593412.5240827, \"EndTime\": 1646593412.7319388, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"csv.encoder.time\": {\"sum\": 205.55615425109863, \"count\": 1, \"min\": 205.55615425109863, \"max\": 205.55615425109863}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593410.1158593, \"EndTime\": 1646593412.5239465, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"evaluate.time\": {\"sum\": 1276.0496139526367, \"count\": 1, \"min\": 1276.0496139526367, \"max\": 1276.0496139526367}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593412.5240827, \"EndTime\": 1646593412.7319388, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"csv.encoder.time\": {\"sum\": 205.55615425109863, \"count\": 1, \"min\": 205.55615425109863, \"max\": 205.55615425109863}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loading entry points\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loading entry points\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Number of server workers: 1\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] loading model...\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] Random Cut Forest model loaded.\u001b[0m\n",
      "\u001b[34mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 1, shingle_size: 1, trees_num_nodes: [353, 359, 349, 339, 357, 361, 359, 363, 373, 373, 355, 371, 363, 337, 359, 361, 371, 327, 361, 357, 361, 353, 349, 369, 357, 361, 365, 363, 345, 369, 345, 361, 353, 343, 357, 349, 337, 341, 365, 365, 359, 349, 359, 337, 355, 353, 345, 361, 361, 363, ], trees_depth: [18, 16, 16, 14, 15, 17, 19, 17, 19, 17, 15, 15, 15, 16, 15, 15, 19, 13, 19, 16, 21, 16, 15, 15, 16, 19, 17, 15, 16, 18, 19, 15, 16, 16, 20, 24, 18, 17, 17, 17, 16, 17, 17, 17, 19, 15, 21, 16, 21, 15, ], max_num_nodes: 373, min_num_nodes: 327, avg_num_nodes: 355, max_tree_depth: 24, min_tree_depth: 13, avg_tree_depth: 16, mem_size: 1851440}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593407.7923996, \"EndTime\": 1646593408.4161294, \"Dimensions\": {}, \"Metrics\": {\"model.bytes\": {\"sum\": 1851440.0, \"count\": 1, \"min\": 1851440, \"max\": 1851440}, \"deserialize_model.time\": {\"sum\": 46.7991828918457, \"count\": 1, \"min\": 46.7991828918457, \"max\": 46.7991828918457}}}\u001b[0m\n",
      "\u001b[34m[03/06/2022 19:03:28 INFO 140416140044096] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2022-03-06 19:03:28 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Number of server workers: 1\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] loading model...\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] Random Cut Forest model loaded.\u001b[0m\n",
      "\u001b[35mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 1, shingle_size: 1, trees_num_nodes: [353, 359, 349, 339, 357, 361, 359, 363, 373, 373, 355, 371, 363, 337, 359, 361, 371, 327, 361, 357, 361, 353, 349, 369, 357, 361, 365, 363, 345, 369, 345, 361, 353, 343, 357, 349, 337, 341, 365, 365, 359, 349, 359, 337, 355, 353, 345, 361, 361, 363, ], trees_depth: [18, 16, 16, 14, 15, 17, 19, 17, 19, 17, 15, 15, 15, 16, 15, 15, 19, 13, 19, 16, 21, 16, 15, 15, 16, 19, 17, 15, 16, 18, 19, 15, 16, 16, 20, 24, 18, 17, 17, 17, 16, 17, 17, 17, 19, 15, 21, 16, 21, 15, ], max_num_nodes: 373, min_num_nodes: 327, avg_num_nodes: 355, max_tree_depth: 24, min_tree_depth: 13, avg_tree_depth: 16, mem_size: 1851440}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593407.7923996, \"EndTime\": 1646593408.4161294, \"Dimensions\": {}, \"Metrics\": {\"model.bytes\": {\"sum\": 1851440.0, \"count\": 1, \"min\": 1851440, \"max\": 1851440}, \"deserialize_model.time\": {\"sum\": 46.7991828918457, \"count\": 1, \"min\": 46.7991828918457, \"max\": 46.7991828918457}}}\u001b[0m\n",
      "\u001b[35m[03/06/2022 19:03:28 INFO 140416140044096] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2022-03-06 19:03:28 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593408.4164748, \"EndTime\": 1646593410.1156788, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593408.4164748, \"EndTime\": 1646593410.1156788, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[32m2022-03-06T19:03:30.124:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593410.1158593, \"EndTime\": 1646593412.5239465, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"evaluate.time\": {\"sum\": 1276.0496139526367, \"count\": 1, \"min\": 1276.0496139526367, \"max\": 1276.0496139526367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646593412.5240827, \"EndTime\": 1646593412.7319388, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"csv.encoder.time\": {\"sum\": 205.55615425109863, \"count\": 1, \"min\": 205.55615425109863, \"max\": 205.55615425109863}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593410.1158593, \"EndTime\": 1646593412.5239465, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"evaluate.time\": {\"sum\": 1276.0496139526367, \"count\": 1, \"min\": 1276.0496139526367, \"max\": 1276.0496139526367}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646593412.5240827, \"EndTime\": 1646593412.7319388, \"Dimensions\": {\"Algorithm\": \"RandomCutForestModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"csv.encoder.time\": {\"sum\": 205.55615425109863, \"count\": 1, \"min\": 205.55615425109863, \"max\": 205.55615425109863}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "batch_input ='s3://feidemo/veritoll/values_and_others.csv' # The location of thetest dataset\n",
    "batch_output = 's3://{}/{}/batch-inference'.format(bucket, prefix) # The location to store the results of the batch transform job\n",
    "transformer = sagemaker.transformer.Transformer(model_name=model_name,instance_count=1, instance_type='ml.m4.xlarge',output_path=batch_output,assemble_with=\"Line\",accept=\"text/csv\")\n",
    "transformer.transform(data=batch_input,join_source=\"Input\",input_filter=\"$[2:2]\", data_type='S3Prefix', content_type='text/csv',split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post processing\n",
    "\n",
    "What we are doing below is to read the output from batch inference to a dataframe, it will not have headers as we can't send it headers for batch inference, we will download, read into a dataframe and provide headers\n",
    "\n",
    "*Note: in Productions you will have a post processing step to add in headers for readability if saving as a csv in S3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://feidemo/veritoll/batch-inference/values_and_others.csv.out to ./values_and_others.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://feidemo/veritoll/batch-inference/values_and_others.csv.out ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infer=pd.read_csv('values_and_others.csv.out', names=['timestamp','values','hour','score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>values</th>\n",
       "      <th>hour</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 00:15:00</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 00:30:00</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 00:45:00</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>1.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  values  hour     score\n",
       "0  2017-01-01 00:00:00      14     0  1.007003\n",
       "1  2017-01-01 00:15:00      39     0  1.007003\n",
       "2  2017-01-01 00:30:00      75     0  1.007003\n",
       "3  2017-01-01 00:45:00     116     0  1.007003\n",
       "4  2017-01-01 01:00:00     124     1  0.853320"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
